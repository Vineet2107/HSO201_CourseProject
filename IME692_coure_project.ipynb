{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1h4kj0gkt4T3_B8V3tQPm2u3K-xmnj9nc",
      "authorship_tag": "ABX9TyM8BUtDSTzTl4UNztMDkcmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vineet2107/HSO201_CourseProject/blob/main/IME692_coure_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T8Mvkxosy3Db"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Course Project IME692/voweltrain_ .csv')\n",
        "df1=pd.read_csv('/content/drive/MyDrive/Course Project IME692/voweltest_.csv')"
      ],
      "metadata": {
        "id": "QY2_0C9Y0VpE"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "xgBsfnZM03e9",
        "outputId": "79cf3374-c80f-465a-bb34-22b82c46f636"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    row.names   y    x.1    x.2    x.3    x.4    x.5    x.6    x.7    x.8  \\\n",
              "0           1   1 -3.639  0.418 -0.670  1.779 -0.168  1.627 -0.388  0.529   \n",
              "1           2   2 -3.327  0.496 -0.694  1.365 -0.265  1.933 -0.363  0.510   \n",
              "2           3   3 -2.120  0.894 -1.576  0.147 -0.707  1.559 -0.579  0.676   \n",
              "3           4   4 -2.287  1.809 -1.498  1.012 -1.053  1.060 -0.567  0.235   \n",
              "4           5   5 -2.598  1.938 -0.846  1.062 -1.633  0.764  0.394 -0.150   \n",
              "5           6   6 -2.852  1.914 -0.755  0.825 -1.588  0.855  0.217 -0.246   \n",
              "6           7   7 -3.482  2.524 -0.433  1.048 -1.995  0.902  0.322  0.450   \n",
              "7           8   8 -3.941  2.305  0.124  1.771 -1.815  0.593 -0.435  0.992   \n",
              "8           9   9 -3.860  2.116 -0.939  0.688 -0.675  1.679 -0.512  0.928   \n",
              "9          10  10 -3.648  1.812 -1.378  1.578  0.065  1.577 -0.466  0.702   \n",
              "10         11  11 -3.032  1.739 -1.141  0.737 -0.834  1.386 -0.575  0.679   \n",
              "11         12   1 -3.653  0.373 -0.600  1.705 -0.222  1.765 -0.353  0.537   \n",
              "12         13   2 -3.237  0.436 -0.860  1.363 -0.251  1.915 -0.395  0.751   \n",
              "13         14   3 -2.135  0.954 -1.632  0.121 -0.704  1.600 -0.628  0.713   \n",
              "14         15   4 -2.304  1.784 -1.506  0.981 -0.961  0.806 -0.294 -0.002   \n",
              "\n",
              "      x.9   x.10  \n",
              "0  -0.874 -0.814  \n",
              "1  -0.621 -0.488  \n",
              "2  -0.809 -0.049  \n",
              "3  -0.091 -0.795  \n",
              "4   0.277 -0.396  \n",
              "5   0.238 -0.365  \n",
              "6   0.377 -0.366  \n",
              "7   0.575 -0.301  \n",
              "8  -0.167 -0.434  \n",
              "9   0.060 -0.836  \n",
              "10 -0.018 -0.823  \n",
              "11 -0.797 -0.813  \n",
              "12 -0.774 -0.327  \n",
              "13 -0.903 -0.027  \n",
              "14  0.119 -0.760  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-325da763-59d4-4d72-a4b9-e18750458f41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row.names</th>\n",
              "      <th>y</th>\n",
              "      <th>x.1</th>\n",
              "      <th>x.2</th>\n",
              "      <th>x.3</th>\n",
              "      <th>x.4</th>\n",
              "      <th>x.5</th>\n",
              "      <th>x.6</th>\n",
              "      <th>x.7</th>\n",
              "      <th>x.8</th>\n",
              "      <th>x.9</th>\n",
              "      <th>x.10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-3.639</td>\n",
              "      <td>0.418</td>\n",
              "      <td>-0.670</td>\n",
              "      <td>1.779</td>\n",
              "      <td>-0.168</td>\n",
              "      <td>1.627</td>\n",
              "      <td>-0.388</td>\n",
              "      <td>0.529</td>\n",
              "      <td>-0.874</td>\n",
              "      <td>-0.814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-3.327</td>\n",
              "      <td>0.496</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>1.365</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>1.933</td>\n",
              "      <td>-0.363</td>\n",
              "      <td>0.510</td>\n",
              "      <td>-0.621</td>\n",
              "      <td>-0.488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>-2.120</td>\n",
              "      <td>0.894</td>\n",
              "      <td>-1.576</td>\n",
              "      <td>0.147</td>\n",
              "      <td>-0.707</td>\n",
              "      <td>1.559</td>\n",
              "      <td>-0.579</td>\n",
              "      <td>0.676</td>\n",
              "      <td>-0.809</td>\n",
              "      <td>-0.049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>-2.287</td>\n",
              "      <td>1.809</td>\n",
              "      <td>-1.498</td>\n",
              "      <td>1.012</td>\n",
              "      <td>-1.053</td>\n",
              "      <td>1.060</td>\n",
              "      <td>-0.567</td>\n",
              "      <td>0.235</td>\n",
              "      <td>-0.091</td>\n",
              "      <td>-0.795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>-2.598</td>\n",
              "      <td>1.938</td>\n",
              "      <td>-0.846</td>\n",
              "      <td>1.062</td>\n",
              "      <td>-1.633</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.394</td>\n",
              "      <td>-0.150</td>\n",
              "      <td>0.277</td>\n",
              "      <td>-0.396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>-2.852</td>\n",
              "      <td>1.914</td>\n",
              "      <td>-0.755</td>\n",
              "      <td>0.825</td>\n",
              "      <td>-1.588</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.217</td>\n",
              "      <td>-0.246</td>\n",
              "      <td>0.238</td>\n",
              "      <td>-0.365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>-3.482</td>\n",
              "      <td>2.524</td>\n",
              "      <td>-0.433</td>\n",
              "      <td>1.048</td>\n",
              "      <td>-1.995</td>\n",
              "      <td>0.902</td>\n",
              "      <td>0.322</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.377</td>\n",
              "      <td>-0.366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>-3.941</td>\n",
              "      <td>2.305</td>\n",
              "      <td>0.124</td>\n",
              "      <td>1.771</td>\n",
              "      <td>-1.815</td>\n",
              "      <td>0.593</td>\n",
              "      <td>-0.435</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.575</td>\n",
              "      <td>-0.301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>-3.860</td>\n",
              "      <td>2.116</td>\n",
              "      <td>-0.939</td>\n",
              "      <td>0.688</td>\n",
              "      <td>-0.675</td>\n",
              "      <td>1.679</td>\n",
              "      <td>-0.512</td>\n",
              "      <td>0.928</td>\n",
              "      <td>-0.167</td>\n",
              "      <td>-0.434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>-3.648</td>\n",
              "      <td>1.812</td>\n",
              "      <td>-1.378</td>\n",
              "      <td>1.578</td>\n",
              "      <td>0.065</td>\n",
              "      <td>1.577</td>\n",
              "      <td>-0.466</td>\n",
              "      <td>0.702</td>\n",
              "      <td>0.060</td>\n",
              "      <td>-0.836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>-3.032</td>\n",
              "      <td>1.739</td>\n",
              "      <td>-1.141</td>\n",
              "      <td>0.737</td>\n",
              "      <td>-0.834</td>\n",
              "      <td>1.386</td>\n",
              "      <td>-0.575</td>\n",
              "      <td>0.679</td>\n",
              "      <td>-0.018</td>\n",
              "      <td>-0.823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>-3.653</td>\n",
              "      <td>0.373</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>1.705</td>\n",
              "      <td>-0.222</td>\n",
              "      <td>1.765</td>\n",
              "      <td>-0.353</td>\n",
              "      <td>0.537</td>\n",
              "      <td>-0.797</td>\n",
              "      <td>-0.813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>-3.237</td>\n",
              "      <td>0.436</td>\n",
              "      <td>-0.860</td>\n",
              "      <td>1.363</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>1.915</td>\n",
              "      <td>-0.395</td>\n",
              "      <td>0.751</td>\n",
              "      <td>-0.774</td>\n",
              "      <td>-0.327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>-2.135</td>\n",
              "      <td>0.954</td>\n",
              "      <td>-1.632</td>\n",
              "      <td>0.121</td>\n",
              "      <td>-0.704</td>\n",
              "      <td>1.600</td>\n",
              "      <td>-0.628</td>\n",
              "      <td>0.713</td>\n",
              "      <td>-0.903</td>\n",
              "      <td>-0.027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>-2.304</td>\n",
              "      <td>1.784</td>\n",
              "      <td>-1.506</td>\n",
              "      <td>0.981</td>\n",
              "      <td>-0.961</td>\n",
              "      <td>0.806</td>\n",
              "      <td>-0.294</td>\n",
              "      <td>-0.002</td>\n",
              "      <td>0.119</td>\n",
              "      <td>-0.760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-325da763-59d4-4d72-a4b9-e18750458f41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-325da763-59d4-4d72-a4b9-e18750458f41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-325da763-59d4-4d72-a4b9-e18750458f41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.y=df.y-1\n",
        "df1.y=df1.y-1"
      ],
      "metadata": {
        "id": "12_wI1Ob6a4_"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AGCegBJY6fDi",
        "outputId": "b4c6bbbf-7a42-4749-ab31-a524c167f960"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     row.names   y    x.1    x.2    x.3    x.4    x.5    x.6    x.7    x.8  \\\n",
              "0            1   0 -3.639  0.418 -0.670  1.779 -0.168  1.627 -0.388  0.529   \n",
              "1            2   1 -3.327  0.496 -0.694  1.365 -0.265  1.933 -0.363  0.510   \n",
              "2            3   2 -2.120  0.894 -1.576  0.147 -0.707  1.559 -0.579  0.676   \n",
              "3            4   3 -2.287  1.809 -1.498  1.012 -1.053  1.060 -0.567  0.235   \n",
              "4            5   4 -2.598  1.938 -0.846  1.062 -1.633  0.764  0.394 -0.150   \n",
              "..         ...  ..    ...    ...    ...    ...    ...    ...    ...    ...   \n",
              "523        524   6 -4.065  2.876 -0.856 -0.221 -0.533  0.232  0.855  0.633   \n",
              "524        525   7 -4.513  4.265 -1.477 -1.090  0.215  0.829  0.342  0.693   \n",
              "525        526   8 -4.651  4.246 -0.823 -0.831  0.666  0.546 -0.300  0.094   \n",
              "526        527   9 -5.034  4.993 -1.633 -0.285  0.398  0.181 -0.211 -0.508   \n",
              "527        528  10 -4.261  1.827 -0.482 -0.194  0.731  0.354 -0.478  0.050   \n",
              "\n",
              "       x.9   x.10  \n",
              "0   -0.874 -0.814  \n",
              "1   -0.621 -0.488  \n",
              "2   -0.809 -0.049  \n",
              "3   -0.091 -0.795  \n",
              "4    0.277 -0.396  \n",
              "..     ...    ...  \n",
              "523 -1.452  0.272  \n",
              "524 -0.601 -0.056  \n",
              "525 -1.343  0.185  \n",
              "526 -0.283  0.304  \n",
              "527 -0.112  0.321  \n",
              "\n",
              "[528 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89ff9906-5854-40b0-8726-922711b4b605\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row.names</th>\n",
              "      <th>y</th>\n",
              "      <th>x.1</th>\n",
              "      <th>x.2</th>\n",
              "      <th>x.3</th>\n",
              "      <th>x.4</th>\n",
              "      <th>x.5</th>\n",
              "      <th>x.6</th>\n",
              "      <th>x.7</th>\n",
              "      <th>x.8</th>\n",
              "      <th>x.9</th>\n",
              "      <th>x.10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-3.639</td>\n",
              "      <td>0.418</td>\n",
              "      <td>-0.670</td>\n",
              "      <td>1.779</td>\n",
              "      <td>-0.168</td>\n",
              "      <td>1.627</td>\n",
              "      <td>-0.388</td>\n",
              "      <td>0.529</td>\n",
              "      <td>-0.874</td>\n",
              "      <td>-0.814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-3.327</td>\n",
              "      <td>0.496</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>1.365</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>1.933</td>\n",
              "      <td>-0.363</td>\n",
              "      <td>0.510</td>\n",
              "      <td>-0.621</td>\n",
              "      <td>-0.488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.120</td>\n",
              "      <td>0.894</td>\n",
              "      <td>-1.576</td>\n",
              "      <td>0.147</td>\n",
              "      <td>-0.707</td>\n",
              "      <td>1.559</td>\n",
              "      <td>-0.579</td>\n",
              "      <td>0.676</td>\n",
              "      <td>-0.809</td>\n",
              "      <td>-0.049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>-2.287</td>\n",
              "      <td>1.809</td>\n",
              "      <td>-1.498</td>\n",
              "      <td>1.012</td>\n",
              "      <td>-1.053</td>\n",
              "      <td>1.060</td>\n",
              "      <td>-0.567</td>\n",
              "      <td>0.235</td>\n",
              "      <td>-0.091</td>\n",
              "      <td>-0.795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>-2.598</td>\n",
              "      <td>1.938</td>\n",
              "      <td>-0.846</td>\n",
              "      <td>1.062</td>\n",
              "      <td>-1.633</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.394</td>\n",
              "      <td>-0.150</td>\n",
              "      <td>0.277</td>\n",
              "      <td>-0.396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>524</td>\n",
              "      <td>6</td>\n",
              "      <td>-4.065</td>\n",
              "      <td>2.876</td>\n",
              "      <td>-0.856</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>-0.533</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.633</td>\n",
              "      <td>-1.452</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>525</td>\n",
              "      <td>7</td>\n",
              "      <td>-4.513</td>\n",
              "      <td>4.265</td>\n",
              "      <td>-1.477</td>\n",
              "      <td>-1.090</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.342</td>\n",
              "      <td>0.693</td>\n",
              "      <td>-0.601</td>\n",
              "      <td>-0.056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>526</td>\n",
              "      <td>8</td>\n",
              "      <td>-4.651</td>\n",
              "      <td>4.246</td>\n",
              "      <td>-0.823</td>\n",
              "      <td>-0.831</td>\n",
              "      <td>0.666</td>\n",
              "      <td>0.546</td>\n",
              "      <td>-0.300</td>\n",
              "      <td>0.094</td>\n",
              "      <td>-1.343</td>\n",
              "      <td>0.185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>527</td>\n",
              "      <td>9</td>\n",
              "      <td>-5.034</td>\n",
              "      <td>4.993</td>\n",
              "      <td>-1.633</td>\n",
              "      <td>-0.285</td>\n",
              "      <td>0.398</td>\n",
              "      <td>0.181</td>\n",
              "      <td>-0.211</td>\n",
              "      <td>-0.508</td>\n",
              "      <td>-0.283</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>528</td>\n",
              "      <td>10</td>\n",
              "      <td>-4.261</td>\n",
              "      <td>1.827</td>\n",
              "      <td>-0.482</td>\n",
              "      <td>-0.194</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.354</td>\n",
              "      <td>-0.478</td>\n",
              "      <td>0.050</td>\n",
              "      <td>-0.112</td>\n",
              "      <td>0.321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>528 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89ff9906-5854-40b0-8726-922711b4b605')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89ff9906-5854-40b0-8726-922711b4b605 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89ff9906-5854-40b0-8726-922711b4b605');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tf.keras.utils.to_categorical(df.y)\n",
        "y_test = tf.keras.utils.to_categorical(df1.y)"
      ],
      "metadata": {
        "id": "Y1i__nz33FKe"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7BWXJ8s3Gac",
        "outputId": "0a9371e0-d45a-473b-def3-8c0288923e70"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(528, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY9XgR7bE9DC",
        "outputId": "aac5e508-55ef-4924-8b4d-e8c51851c3fe"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(462, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I67TcHNf6NmG",
        "outputId": "e738e0c5-97b5-42b4-99f4-762019ba57dc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df[df.columns[2:12]]"
      ],
      "metadata": {
        "id": "s4qIf0ak3Nbz"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1=df1[df1.columns[2:12]]"
      ],
      "metadata": {
        "id": "0evXTiPxFGAX"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uERc-Rav3s_u",
        "outputId": "0fcad6b2-74cd-4e2f-ebb1-533cb9152f3f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       x.1    x.2    x.3    x.4    x.5    x.6    x.7    x.8    x.9   x.10\n",
              "0   -3.639  0.418 -0.670  1.779 -0.168  1.627 -0.388  0.529 -0.874 -0.814\n",
              "1   -3.327  0.496 -0.694  1.365 -0.265  1.933 -0.363  0.510 -0.621 -0.488\n",
              "2   -2.120  0.894 -1.576  0.147 -0.707  1.559 -0.579  0.676 -0.809 -0.049\n",
              "3   -2.287  1.809 -1.498  1.012 -1.053  1.060 -0.567  0.235 -0.091 -0.795\n",
              "4   -2.598  1.938 -0.846  1.062 -1.633  0.764  0.394 -0.150  0.277 -0.396\n",
              "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
              "523 -4.065  2.876 -0.856 -0.221 -0.533  0.232  0.855  0.633 -1.452  0.272\n",
              "524 -4.513  4.265 -1.477 -1.090  0.215  0.829  0.342  0.693 -0.601 -0.056\n",
              "525 -4.651  4.246 -0.823 -0.831  0.666  0.546 -0.300  0.094 -1.343  0.185\n",
              "526 -5.034  4.993 -1.633 -0.285  0.398  0.181 -0.211 -0.508 -0.283  0.304\n",
              "527 -4.261  1.827 -0.482 -0.194  0.731  0.354 -0.478  0.050 -0.112  0.321\n",
              "\n",
              "[528 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-263a97d5-e4db-4c2e-b7fe-5a8e39b597ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x.1</th>\n",
              "      <th>x.2</th>\n",
              "      <th>x.3</th>\n",
              "      <th>x.4</th>\n",
              "      <th>x.5</th>\n",
              "      <th>x.6</th>\n",
              "      <th>x.7</th>\n",
              "      <th>x.8</th>\n",
              "      <th>x.9</th>\n",
              "      <th>x.10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-3.639</td>\n",
              "      <td>0.418</td>\n",
              "      <td>-0.670</td>\n",
              "      <td>1.779</td>\n",
              "      <td>-0.168</td>\n",
              "      <td>1.627</td>\n",
              "      <td>-0.388</td>\n",
              "      <td>0.529</td>\n",
              "      <td>-0.874</td>\n",
              "      <td>-0.814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-3.327</td>\n",
              "      <td>0.496</td>\n",
              "      <td>-0.694</td>\n",
              "      <td>1.365</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>1.933</td>\n",
              "      <td>-0.363</td>\n",
              "      <td>0.510</td>\n",
              "      <td>-0.621</td>\n",
              "      <td>-0.488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.120</td>\n",
              "      <td>0.894</td>\n",
              "      <td>-1.576</td>\n",
              "      <td>0.147</td>\n",
              "      <td>-0.707</td>\n",
              "      <td>1.559</td>\n",
              "      <td>-0.579</td>\n",
              "      <td>0.676</td>\n",
              "      <td>-0.809</td>\n",
              "      <td>-0.049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.287</td>\n",
              "      <td>1.809</td>\n",
              "      <td>-1.498</td>\n",
              "      <td>1.012</td>\n",
              "      <td>-1.053</td>\n",
              "      <td>1.060</td>\n",
              "      <td>-0.567</td>\n",
              "      <td>0.235</td>\n",
              "      <td>-0.091</td>\n",
              "      <td>-0.795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.598</td>\n",
              "      <td>1.938</td>\n",
              "      <td>-0.846</td>\n",
              "      <td>1.062</td>\n",
              "      <td>-1.633</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.394</td>\n",
              "      <td>-0.150</td>\n",
              "      <td>0.277</td>\n",
              "      <td>-0.396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>-4.065</td>\n",
              "      <td>2.876</td>\n",
              "      <td>-0.856</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>-0.533</td>\n",
              "      <td>0.232</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.633</td>\n",
              "      <td>-1.452</td>\n",
              "      <td>0.272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>-4.513</td>\n",
              "      <td>4.265</td>\n",
              "      <td>-1.477</td>\n",
              "      <td>-1.090</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.829</td>\n",
              "      <td>0.342</td>\n",
              "      <td>0.693</td>\n",
              "      <td>-0.601</td>\n",
              "      <td>-0.056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>-4.651</td>\n",
              "      <td>4.246</td>\n",
              "      <td>-0.823</td>\n",
              "      <td>-0.831</td>\n",
              "      <td>0.666</td>\n",
              "      <td>0.546</td>\n",
              "      <td>-0.300</td>\n",
              "      <td>0.094</td>\n",
              "      <td>-1.343</td>\n",
              "      <td>0.185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>-5.034</td>\n",
              "      <td>4.993</td>\n",
              "      <td>-1.633</td>\n",
              "      <td>-0.285</td>\n",
              "      <td>0.398</td>\n",
              "      <td>0.181</td>\n",
              "      <td>-0.211</td>\n",
              "      <td>-0.508</td>\n",
              "      <td>-0.283</td>\n",
              "      <td>0.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>-4.261</td>\n",
              "      <td>1.827</td>\n",
              "      <td>-0.482</td>\n",
              "      <td>-0.194</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.354</td>\n",
              "      <td>-0.478</td>\n",
              "      <td>0.050</td>\n",
              "      <td>-0.112</td>\n",
              "      <td>0.321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>528 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-263a97d5-e4db-4c2e-b7fe-5a8e39b597ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-263a97d5-e4db-4c2e-b7fe-5a8e39b597ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-263a97d5-e4db-4c2e-b7fe-5a8e39b597ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.array(x)\n",
        "x_test=np.array(x1)"
      ],
      "metadata": {
        "id": "fspdZpD03t91"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3OOsMSCGGdA",
        "outputId": "7f36f962-50d5-474b-8db4-b39e6b9934ad"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(528, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdSJSuYLGKh1",
        "outputId": "a90fe6c9-c186-4e7f-d022-c3f8db3e6a32"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(462, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perms = np.random.permutation(528)"
      ],
      "metadata": {
        "id": "O5XfvtV8HndO"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train[perms]\n",
        "y_train=y_train[perms]"
      ],
      "metadata": {
        "id": "2zmlEZvFH_8v"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qyEzVb2QH_5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LvvLwAi30XW",
        "outputId": "4ba33f0d-0432-4b71-bc0a-b3e0688bbbf0"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.261,  1.827, -0.482, ...,  0.05 , -0.112,  0.321],\n",
              "       [-3.601,  0.742, -0.238, ...,  0.844,  0.558,  0.659],\n",
              "       [-2.55 ,  2.629,  0.084, ...,  0.961,  0.032, -0.589],\n",
              "       ...,\n",
              "       [-2.558,  0.755, -0.66 , ..., -0.531, -0.062,  0.418],\n",
              "       [-2.559,  2.3  ,  0.408, ...,  0.975,  0.07 , -0.47 ],\n",
              "       [-3.406,  2.403,  1.025, ...,  1.541, -0.304, -0.671]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=x_train\n",
        "X_test=x_test"
      ],
      "metadata": {
        "id": "GB69PgSKGEQO"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imported necessary packages for model\n",
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Activation\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ATcrErwW31it"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = [x_train.shape[1]]"
      ],
      "metadata": {
        "id": "Gw_170YV5FKV"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sequential MLP model \n",
        "model = tf.keras.Sequential([\n",
        "    layers.BatchNormalization(input_shape=input_shape),\n",
        "    layers.Dense(20, activation='relu'),\n",
        "    layers.Dropout(0.05),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dropout(0.05),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dense(11, activation = 'sigmoid'),\n",
        "])\n"
      ],
      "metadata": {
        "id": "BT_TRWIs6uLr"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=optimizer,loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4nLaTOs76z1L"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training model\n",
        "epochs = 500\n",
        "history = model.fit(x_train, y_train, validation_split=0.1, batch_size=16,\n",
        "                    epochs=epochs, verbose=1,\n",
        "                    #validation_data=(X_test, y_test)\n",
        ")\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[0:, ['loss', 'val_loss']].plot()\n",
        "print((\"Minimum Validation Loss: {:0.4f}\").format(history_df['val_loss'].min()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ATSu7pnl7JWi",
        "outputId": "6cf708aa-5207-4ef5-9e4a-3ff5b2141a7b"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "30/30 [==============================] - 1s 10ms/step - loss: 2.9324 - accuracy: 0.0737 - val_loss: 2.4566 - val_accuracy: 0.0943\n",
            "Epoch 2/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.6213 - accuracy: 0.1095 - val_loss: 2.4200 - val_accuracy: 0.1321\n",
            "Epoch 3/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.4723 - accuracy: 0.1684 - val_loss: 2.3680 - val_accuracy: 0.1698\n",
            "Epoch 4/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 2.3361 - accuracy: 0.1874 - val_loss: 2.2919 - val_accuracy: 0.1887\n",
            "Epoch 5/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.2148 - accuracy: 0.2274 - val_loss: 2.1845 - val_accuracy: 0.2830\n",
            "Epoch 6/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 2.0967 - accuracy: 0.2421 - val_loss: 2.0782 - val_accuracy: 0.2453\n",
            "Epoch 7/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.0192 - accuracy: 0.2989 - val_loss: 1.9824 - val_accuracy: 0.3208\n",
            "Epoch 8/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 2.0086 - accuracy: 0.2947 - val_loss: 1.8856 - val_accuracy: 0.3396\n",
            "Epoch 9/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.9218 - accuracy: 0.3179 - val_loss: 1.7957 - val_accuracy: 0.4528\n",
            "Epoch 10/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.9161 - accuracy: 0.3074 - val_loss: 1.7265 - val_accuracy: 0.4717\n",
            "Epoch 11/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.8099 - accuracy: 0.3621 - val_loss: 1.6683 - val_accuracy: 0.4717\n",
            "Epoch 12/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.7840 - accuracy: 0.3579 - val_loss: 1.6035 - val_accuracy: 0.4906\n",
            "Epoch 13/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.7116 - accuracy: 0.3747 - val_loss: 1.5465 - val_accuracy: 0.4906\n",
            "Epoch 14/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.6879 - accuracy: 0.3811 - val_loss: 1.5012 - val_accuracy: 0.5094\n",
            "Epoch 15/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.6504 - accuracy: 0.4358 - val_loss: 1.4551 - val_accuracy: 0.5094\n",
            "Epoch 16/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.5934 - accuracy: 0.4189 - val_loss: 1.3994 - val_accuracy: 0.5472\n",
            "Epoch 17/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.5681 - accuracy: 0.4253 - val_loss: 1.3575 - val_accuracy: 0.5283\n",
            "Epoch 18/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.5361 - accuracy: 0.4484 - val_loss: 1.3069 - val_accuracy: 0.5472\n",
            "Epoch 19/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.5147 - accuracy: 0.4547 - val_loss: 1.2745 - val_accuracy: 0.5849\n",
            "Epoch 20/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.5131 - accuracy: 0.4274 - val_loss: 1.2531 - val_accuracy: 0.5660\n",
            "Epoch 21/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.4917 - accuracy: 0.4779 - val_loss: 1.2151 - val_accuracy: 0.6038\n",
            "Epoch 22/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.4219 - accuracy: 0.4926 - val_loss: 1.1860 - val_accuracy: 0.6226\n",
            "Epoch 23/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.3838 - accuracy: 0.5158 - val_loss: 1.1512 - val_accuracy: 0.6226\n",
            "Epoch 24/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.3862 - accuracy: 0.4800 - val_loss: 1.1258 - val_accuracy: 0.6415\n",
            "Epoch 25/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.3835 - accuracy: 0.5053 - val_loss: 1.0925 - val_accuracy: 0.6792\n",
            "Epoch 26/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.3151 - accuracy: 0.5389 - val_loss: 1.0511 - val_accuracy: 0.7358\n",
            "Epoch 27/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.3645 - accuracy: 0.5158 - val_loss: 1.0156 - val_accuracy: 0.7170\n",
            "Epoch 28/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.2973 - accuracy: 0.5432 - val_loss: 0.9978 - val_accuracy: 0.7547\n",
            "Epoch 29/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.3032 - accuracy: 0.5453 - val_loss: 0.9771 - val_accuracy: 0.7358\n",
            "Epoch 30/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.2895 - accuracy: 0.5263 - val_loss: 0.9545 - val_accuracy: 0.7358\n",
            "Epoch 31/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 1.2880 - accuracy: 0.5326 - val_loss: 0.9385 - val_accuracy: 0.7547\n",
            "Epoch 32/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.2113 - accuracy: 0.5811 - val_loss: 0.9131 - val_accuracy: 0.7547\n",
            "Epoch 33/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.2405 - accuracy: 0.5705 - val_loss: 0.8903 - val_accuracy: 0.7736\n",
            "Epoch 34/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.2572 - accuracy: 0.5537 - val_loss: 0.8806 - val_accuracy: 0.7736\n",
            "Epoch 35/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.1586 - accuracy: 0.5916 - val_loss: 0.8723 - val_accuracy: 0.7736\n",
            "Epoch 36/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.2006 - accuracy: 0.5789 - val_loss: 0.8639 - val_accuracy: 0.6981\n",
            "Epoch 37/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.1400 - accuracy: 0.5832 - val_loss: 0.8476 - val_accuracy: 0.7547\n",
            "Epoch 38/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.1385 - accuracy: 0.5937 - val_loss: 0.8365 - val_accuracy: 0.7547\n",
            "Epoch 39/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.1478 - accuracy: 0.5621 - val_loss: 0.8122 - val_accuracy: 0.7547\n",
            "Epoch 40/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.1041 - accuracy: 0.6189 - val_loss: 0.8040 - val_accuracy: 0.7736\n",
            "Epoch 41/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.1253 - accuracy: 0.5789 - val_loss: 0.7945 - val_accuracy: 0.8302\n",
            "Epoch 42/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.1159 - accuracy: 0.6042 - val_loss: 0.7710 - val_accuracy: 0.8113\n",
            "Epoch 43/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.1245 - accuracy: 0.5811 - val_loss: 0.7506 - val_accuracy: 0.7925\n",
            "Epoch 44/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 1.0584 - accuracy: 0.6042 - val_loss: 0.7277 - val_accuracy: 0.8302\n",
            "Epoch 45/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.9894 - accuracy: 0.6337 - val_loss: 0.7185 - val_accuracy: 0.8302\n",
            "Epoch 46/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.0265 - accuracy: 0.6526 - val_loss: 0.7076 - val_accuracy: 0.8113\n",
            "Epoch 47/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.0554 - accuracy: 0.5958 - val_loss: 0.7145 - val_accuracy: 0.8113\n",
            "Epoch 48/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.0470 - accuracy: 0.6358 - val_loss: 0.6971 - val_accuracy: 0.8302\n",
            "Epoch 49/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.0322 - accuracy: 0.6063 - val_loss: 0.6835 - val_accuracy: 0.7925\n",
            "Epoch 50/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.0763 - accuracy: 0.5958 - val_loss: 0.6693 - val_accuracy: 0.8491\n",
            "Epoch 51/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.1200 - accuracy: 0.5747 - val_loss: 0.6492 - val_accuracy: 0.8679\n",
            "Epoch 52/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9565 - accuracy: 0.6358 - val_loss: 0.6592 - val_accuracy: 0.8302\n",
            "Epoch 53/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9863 - accuracy: 0.6421 - val_loss: 0.6587 - val_accuracy: 0.8302\n",
            "Epoch 54/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.0136 - accuracy: 0.6442 - val_loss: 0.6417 - val_accuracy: 0.8302\n",
            "Epoch 55/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.0065 - accuracy: 0.6358 - val_loss: 0.6388 - val_accuracy: 0.8302\n",
            "Epoch 56/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9402 - accuracy: 0.6484 - val_loss: 0.6256 - val_accuracy: 0.8679\n",
            "Epoch 57/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.0030 - accuracy: 0.6379 - val_loss: 0.6126 - val_accuracy: 0.8679\n",
            "Epoch 58/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9702 - accuracy: 0.6611 - val_loss: 0.5918 - val_accuracy: 0.9057\n",
            "Epoch 59/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.0015 - accuracy: 0.6232 - val_loss: 0.5833 - val_accuracy: 0.8491\n",
            "Epoch 60/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9231 - accuracy: 0.6505 - val_loss: 0.5972 - val_accuracy: 0.8491\n",
            "Epoch 61/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.0037 - accuracy: 0.6021 - val_loss: 0.5973 - val_accuracy: 0.8679\n",
            "Epoch 62/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9394 - accuracy: 0.6295 - val_loss: 0.5897 - val_accuracy: 0.8491\n",
            "Epoch 63/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9990 - accuracy: 0.6211 - val_loss: 0.5725 - val_accuracy: 0.8491\n",
            "Epoch 64/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9413 - accuracy: 0.6316 - val_loss: 0.5708 - val_accuracy: 0.8868\n",
            "Epoch 65/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.0166 - accuracy: 0.6274 - val_loss: 0.5550 - val_accuracy: 0.8868\n",
            "Epoch 66/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.9862 - accuracy: 0.6400 - val_loss: 0.5463 - val_accuracy: 0.9057\n",
            "Epoch 67/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9586 - accuracy: 0.6505 - val_loss: 0.5510 - val_accuracy: 0.8868\n",
            "Epoch 68/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9934 - accuracy: 0.6147 - val_loss: 0.5295 - val_accuracy: 0.8868\n",
            "Epoch 69/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8965 - accuracy: 0.6442 - val_loss: 0.5254 - val_accuracy: 0.8868\n",
            "Epoch 70/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8727 - accuracy: 0.6821 - val_loss: 0.5344 - val_accuracy: 0.8868\n",
            "Epoch 71/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9249 - accuracy: 0.6400 - val_loss: 0.5479 - val_accuracy: 0.8868\n",
            "Epoch 72/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9021 - accuracy: 0.6611 - val_loss: 0.5290 - val_accuracy: 0.8679\n",
            "Epoch 73/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9007 - accuracy: 0.6547 - val_loss: 0.5139 - val_accuracy: 0.9057\n",
            "Epoch 74/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9279 - accuracy: 0.6653 - val_loss: 0.5175 - val_accuracy: 0.8868\n",
            "Epoch 75/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 1.0115 - accuracy: 0.6147 - val_loss: 0.4856 - val_accuracy: 0.9057\n",
            "Epoch 76/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9146 - accuracy: 0.6674 - val_loss: 0.4852 - val_accuracy: 0.9057\n",
            "Epoch 77/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9359 - accuracy: 0.6589 - val_loss: 0.4846 - val_accuracy: 0.8868\n",
            "Epoch 78/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9210 - accuracy: 0.6568 - val_loss: 0.4797 - val_accuracy: 0.9057\n",
            "Epoch 79/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9224 - accuracy: 0.6316 - val_loss: 0.4821 - val_accuracy: 0.9245\n",
            "Epoch 80/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.0369 - accuracy: 0.6189 - val_loss: 0.4881 - val_accuracy: 0.8868\n",
            "Epoch 81/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8880 - accuracy: 0.6547 - val_loss: 0.4719 - val_accuracy: 0.9245\n",
            "Epoch 82/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9087 - accuracy: 0.6505 - val_loss: 0.4573 - val_accuracy: 0.9245\n",
            "Epoch 83/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8977 - accuracy: 0.6547 - val_loss: 0.4462 - val_accuracy: 0.9434\n",
            "Epoch 84/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.9175 - accuracy: 0.6800 - val_loss: 0.4502 - val_accuracy: 0.9057\n",
            "Epoch 85/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 1.0120 - accuracy: 0.6021 - val_loss: 0.4461 - val_accuracy: 0.9057\n",
            "Epoch 86/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9000 - accuracy: 0.6589 - val_loss: 0.4405 - val_accuracy: 0.9057\n",
            "Epoch 87/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8837 - accuracy: 0.6758 - val_loss: 0.4349 - val_accuracy: 0.9245\n",
            "Epoch 88/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8901 - accuracy: 0.6379 - val_loss: 0.4415 - val_accuracy: 0.9245\n",
            "Epoch 89/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9011 - accuracy: 0.6695 - val_loss: 0.4481 - val_accuracy: 0.9245\n",
            "Epoch 90/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8249 - accuracy: 0.6905 - val_loss: 0.4425 - val_accuracy: 0.9245\n",
            "Epoch 91/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9089 - accuracy: 0.6484 - val_loss: 0.4336 - val_accuracy: 0.9245\n",
            "Epoch 92/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8334 - accuracy: 0.6674 - val_loss: 0.4391 - val_accuracy: 0.9057\n",
            "Epoch 93/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8514 - accuracy: 0.6653 - val_loss: 0.4218 - val_accuracy: 0.9623\n",
            "Epoch 94/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9251 - accuracy: 0.6674 - val_loss: 0.4330 - val_accuracy: 0.9245\n",
            "Epoch 95/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9428 - accuracy: 0.6505 - val_loss: 0.4275 - val_accuracy: 0.9623\n",
            "Epoch 96/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8004 - accuracy: 0.7200 - val_loss: 0.4268 - val_accuracy: 0.9434\n",
            "Epoch 97/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8578 - accuracy: 0.6695 - val_loss: 0.4213 - val_accuracy: 0.9623\n",
            "Epoch 98/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9114 - accuracy: 0.6716 - val_loss: 0.4270 - val_accuracy: 0.9057\n",
            "Epoch 99/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8110 - accuracy: 0.6905 - val_loss: 0.4227 - val_accuracy: 0.9057\n",
            "Epoch 100/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8814 - accuracy: 0.6505 - val_loss: 0.4221 - val_accuracy: 0.9245\n",
            "Epoch 101/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8950 - accuracy: 0.6589 - val_loss: 0.4273 - val_accuracy: 0.9434\n",
            "Epoch 102/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9641 - accuracy: 0.6379 - val_loss: 0.4080 - val_accuracy: 0.9434\n",
            "Epoch 103/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8969 - accuracy: 0.6568 - val_loss: 0.4160 - val_accuracy: 0.9434\n",
            "Epoch 104/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8643 - accuracy: 0.6842 - val_loss: 0.4163 - val_accuracy: 0.9434\n",
            "Epoch 105/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9445 - accuracy: 0.6526 - val_loss: 0.4148 - val_accuracy: 0.9245\n",
            "Epoch 106/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8123 - accuracy: 0.7053 - val_loss: 0.4160 - val_accuracy: 0.9434\n",
            "Epoch 107/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.9435 - accuracy: 0.6589 - val_loss: 0.4198 - val_accuracy: 0.9434\n",
            "Epoch 108/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8527 - accuracy: 0.7011 - val_loss: 0.4185 - val_accuracy: 0.9434\n",
            "Epoch 109/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8525 - accuracy: 0.6653 - val_loss: 0.4211 - val_accuracy: 0.9434\n",
            "Epoch 110/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8674 - accuracy: 0.6547 - val_loss: 0.4049 - val_accuracy: 0.9245\n",
            "Epoch 111/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8395 - accuracy: 0.6863 - val_loss: 0.4126 - val_accuracy: 0.9057\n",
            "Epoch 112/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8747 - accuracy: 0.6674 - val_loss: 0.4023 - val_accuracy: 0.9057\n",
            "Epoch 113/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8621 - accuracy: 0.6653 - val_loss: 0.4009 - val_accuracy: 0.9057\n",
            "Epoch 114/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8656 - accuracy: 0.6484 - val_loss: 0.3930 - val_accuracy: 0.9245\n",
            "Epoch 115/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8405 - accuracy: 0.7032 - val_loss: 0.3995 - val_accuracy: 0.9245\n",
            "Epoch 116/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9387 - accuracy: 0.6484 - val_loss: 0.3969 - val_accuracy: 0.8868\n",
            "Epoch 117/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8667 - accuracy: 0.6947 - val_loss: 0.4074 - val_accuracy: 0.9057\n",
            "Epoch 118/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.9033 - accuracy: 0.6337 - val_loss: 0.4008 - val_accuracy: 0.8868\n",
            "Epoch 119/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8406 - accuracy: 0.6842 - val_loss: 0.3846 - val_accuracy: 0.9434\n",
            "Epoch 120/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8307 - accuracy: 0.6779 - val_loss: 0.3831 - val_accuracy: 0.9434\n",
            "Epoch 121/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8771 - accuracy: 0.6716 - val_loss: 0.3851 - val_accuracy: 0.9434\n",
            "Epoch 122/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7994 - accuracy: 0.7347 - val_loss: 0.3930 - val_accuracy: 0.9434\n",
            "Epoch 123/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8553 - accuracy: 0.6863 - val_loss: 0.3931 - val_accuracy: 0.9434\n",
            "Epoch 124/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8003 - accuracy: 0.6968 - val_loss: 0.3728 - val_accuracy: 0.9623\n",
            "Epoch 125/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7787 - accuracy: 0.7411 - val_loss: 0.3868 - val_accuracy: 0.9623\n",
            "Epoch 126/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8742 - accuracy: 0.6695 - val_loss: 0.3923 - val_accuracy: 0.9245\n",
            "Epoch 127/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8317 - accuracy: 0.6589 - val_loss: 0.3796 - val_accuracy: 0.9245\n",
            "Epoch 128/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8410 - accuracy: 0.6947 - val_loss: 0.3690 - val_accuracy: 0.9245\n",
            "Epoch 129/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8303 - accuracy: 0.6947 - val_loss: 0.3785 - val_accuracy: 0.9245\n",
            "Epoch 130/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8224 - accuracy: 0.6737 - val_loss: 0.3860 - val_accuracy: 0.9245\n",
            "Epoch 131/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8058 - accuracy: 0.6989 - val_loss: 0.3798 - val_accuracy: 0.9057\n",
            "Epoch 132/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7749 - accuracy: 0.7158 - val_loss: 0.3888 - val_accuracy: 0.8868\n",
            "Epoch 133/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7954 - accuracy: 0.7221 - val_loss: 0.3856 - val_accuracy: 0.8868\n",
            "Epoch 134/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8289 - accuracy: 0.6989 - val_loss: 0.3728 - val_accuracy: 0.8868\n",
            "Epoch 135/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.8808 - accuracy: 0.6779 - val_loss: 0.3584 - val_accuracy: 0.8868\n",
            "Epoch 136/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7979 - accuracy: 0.6842 - val_loss: 0.3555 - val_accuracy: 0.9245\n",
            "Epoch 137/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8505 - accuracy: 0.6926 - val_loss: 0.3534 - val_accuracy: 0.9434\n",
            "Epoch 138/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7481 - accuracy: 0.7179 - val_loss: 0.3488 - val_accuracy: 0.9245\n",
            "Epoch 139/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7698 - accuracy: 0.7137 - val_loss: 0.3529 - val_accuracy: 0.9434\n",
            "Epoch 140/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8147 - accuracy: 0.7074 - val_loss: 0.3315 - val_accuracy: 0.9434\n",
            "Epoch 141/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8102 - accuracy: 0.6989 - val_loss: 0.3425 - val_accuracy: 0.9434\n",
            "Epoch 142/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7946 - accuracy: 0.6863 - val_loss: 0.3278 - val_accuracy: 0.9434\n",
            "Epoch 143/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7831 - accuracy: 0.7074 - val_loss: 0.3321 - val_accuracy: 0.9623\n",
            "Epoch 144/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8285 - accuracy: 0.6800 - val_loss: 0.3193 - val_accuracy: 0.9434\n",
            "Epoch 145/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8483 - accuracy: 0.6758 - val_loss: 0.3322 - val_accuracy: 0.9434\n",
            "Epoch 146/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.7284 - val_loss: 0.3360 - val_accuracy: 0.9811\n",
            "Epoch 147/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7945 - accuracy: 0.6884 - val_loss: 0.3345 - val_accuracy: 0.9623\n",
            "Epoch 148/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7553 - accuracy: 0.7242 - val_loss: 0.3316 - val_accuracy: 0.9623\n",
            "Epoch 149/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8663 - accuracy: 0.6779 - val_loss: 0.3282 - val_accuracy: 0.9811\n",
            "Epoch 150/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7808 - accuracy: 0.7053 - val_loss: 0.3316 - val_accuracy: 0.9623\n",
            "Epoch 151/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7704 - accuracy: 0.7053 - val_loss: 0.3278 - val_accuracy: 0.9623\n",
            "Epoch 152/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7963 - accuracy: 0.7074 - val_loss: 0.3320 - val_accuracy: 0.9434\n",
            "Epoch 153/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7394 - accuracy: 0.7368 - val_loss: 0.3265 - val_accuracy: 0.9434\n",
            "Epoch 154/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7922 - accuracy: 0.6821 - val_loss: 0.3097 - val_accuracy: 0.9623\n",
            "Epoch 155/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7817 - accuracy: 0.7074 - val_loss: 0.3270 - val_accuracy: 0.9245\n",
            "Epoch 156/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7890 - accuracy: 0.6968 - val_loss: 0.3295 - val_accuracy: 0.9434\n",
            "Epoch 157/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8342 - accuracy: 0.6947 - val_loss: 0.3345 - val_accuracy: 0.9245\n",
            "Epoch 158/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7881 - accuracy: 0.6863 - val_loss: 0.3108 - val_accuracy: 0.9811\n",
            "Epoch 159/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7378 - accuracy: 0.7158 - val_loss: 0.3177 - val_accuracy: 0.9434\n",
            "Epoch 160/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.7095 - val_loss: 0.3240 - val_accuracy: 0.9245\n",
            "Epoch 161/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8397 - accuracy: 0.6695 - val_loss: 0.3242 - val_accuracy: 0.9245\n",
            "Epoch 162/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7839 - accuracy: 0.6989 - val_loss: 0.3121 - val_accuracy: 0.9434\n",
            "Epoch 163/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7761 - accuracy: 0.7284 - val_loss: 0.3300 - val_accuracy: 0.9245\n",
            "Epoch 164/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8479 - accuracy: 0.7053 - val_loss: 0.3318 - val_accuracy: 0.9434\n",
            "Epoch 165/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7304 - accuracy: 0.7221 - val_loss: 0.3430 - val_accuracy: 0.9057\n",
            "Epoch 166/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7660 - accuracy: 0.7137 - val_loss: 0.3266 - val_accuracy: 0.9623\n",
            "Epoch 167/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7889 - accuracy: 0.7116 - val_loss: 0.3001 - val_accuracy: 0.9623\n",
            "Epoch 168/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.7516 - val_loss: 0.3015 - val_accuracy: 0.9623\n",
            "Epoch 169/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7602 - accuracy: 0.7179 - val_loss: 0.2987 - val_accuracy: 0.9623\n",
            "Epoch 170/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8217 - accuracy: 0.6821 - val_loss: 0.2971 - val_accuracy: 0.9623\n",
            "Epoch 171/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7548 - accuracy: 0.7221 - val_loss: 0.3090 - val_accuracy: 0.9623\n",
            "Epoch 172/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7809 - accuracy: 0.7032 - val_loss: 0.3075 - val_accuracy: 0.9623\n",
            "Epoch 173/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8148 - accuracy: 0.6863 - val_loss: 0.3016 - val_accuracy: 0.9623\n",
            "Epoch 174/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7727 - accuracy: 0.7032 - val_loss: 0.3036 - val_accuracy: 0.9434\n",
            "Epoch 175/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8057 - accuracy: 0.7074 - val_loss: 0.2864 - val_accuracy: 0.9623\n",
            "Epoch 176/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8135 - accuracy: 0.6863 - val_loss: 0.2761 - val_accuracy: 0.9623\n",
            "Epoch 177/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8233 - accuracy: 0.6947 - val_loss: 0.2843 - val_accuracy: 0.9434\n",
            "Epoch 178/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.7495 - val_loss: 0.2841 - val_accuracy: 0.9623\n",
            "Epoch 179/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7748 - accuracy: 0.7389 - val_loss: 0.2835 - val_accuracy: 0.9623\n",
            "Epoch 180/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7101 - accuracy: 0.7537 - val_loss: 0.2961 - val_accuracy: 0.9623\n",
            "Epoch 181/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7033 - accuracy: 0.7368 - val_loss: 0.3015 - val_accuracy: 0.9623\n",
            "Epoch 182/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7323 - accuracy: 0.7263 - val_loss: 0.2967 - val_accuracy: 0.9434\n",
            "Epoch 183/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7857 - accuracy: 0.6821 - val_loss: 0.2940 - val_accuracy: 0.9434\n",
            "Epoch 184/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7487 - accuracy: 0.7347 - val_loss: 0.2830 - val_accuracy: 0.9623\n",
            "Epoch 185/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7584 - accuracy: 0.6968 - val_loss: 0.2849 - val_accuracy: 0.9623\n",
            "Epoch 186/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7179 - accuracy: 0.7347 - val_loss: 0.2830 - val_accuracy: 0.9623\n",
            "Epoch 187/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7887 - accuracy: 0.7095 - val_loss: 0.2826 - val_accuracy: 0.9811\n",
            "Epoch 188/500\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.7441 - accuracy: 0.6989 - val_loss: 0.2884 - val_accuracy: 0.9811\n",
            "Epoch 189/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.7066 - accuracy: 0.7347 - val_loss: 0.2830 - val_accuracy: 0.9623\n",
            "Epoch 190/500\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.8877 - accuracy: 0.6779 - val_loss: 0.2727 - val_accuracy: 0.9811\n",
            "Epoch 191/500\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.7299 - accuracy: 0.7432 - val_loss: 0.2668 - val_accuracy: 0.9811\n",
            "Epoch 192/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.7547 - accuracy: 0.7221 - val_loss: 0.2690 - val_accuracy: 0.9811\n",
            "Epoch 193/500\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.6979 - accuracy: 0.7347 - val_loss: 0.2754 - val_accuracy: 0.9811\n",
            "Epoch 194/500\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.7589 - accuracy: 0.7116 - val_loss: 0.2877 - val_accuracy: 0.9811\n",
            "Epoch 195/500\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.9691 - accuracy: 0.6716 - val_loss: 0.2817 - val_accuracy: 0.9623\n",
            "Epoch 196/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.6952 - accuracy: 0.7242 - val_loss: 0.2694 - val_accuracy: 0.9811\n",
            "Epoch 197/500\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.7469 - accuracy: 0.7158 - val_loss: 0.2701 - val_accuracy: 0.9811\n",
            "Epoch 198/500\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.7590 - accuracy: 0.7116 - val_loss: 0.2695 - val_accuracy: 0.9811\n",
            "Epoch 199/500\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.6746 - accuracy: 0.7537 - val_loss: 0.2719 - val_accuracy: 0.9811\n",
            "Epoch 200/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.8370 - accuracy: 0.6884 - val_loss: 0.2675 - val_accuracy: 0.9623\n",
            "Epoch 201/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7299 - accuracy: 0.7347 - val_loss: 0.2660 - val_accuracy: 0.9623\n",
            "Epoch 202/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7333 - accuracy: 0.7389 - val_loss: 0.2699 - val_accuracy: 0.9623\n",
            "Epoch 203/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8426 - accuracy: 0.7074 - val_loss: 0.2739 - val_accuracy: 0.9623\n",
            "Epoch 204/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8325 - accuracy: 0.6842 - val_loss: 0.2790 - val_accuracy: 0.9434\n",
            "Epoch 205/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7266 - accuracy: 0.7495 - val_loss: 0.2806 - val_accuracy: 0.9245\n",
            "Epoch 206/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8416 - accuracy: 0.7032 - val_loss: 0.2839 - val_accuracy: 0.9245\n",
            "Epoch 207/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7017 - accuracy: 0.7495 - val_loss: 0.2879 - val_accuracy: 0.9245\n",
            "Epoch 208/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7407 - accuracy: 0.7263 - val_loss: 0.2827 - val_accuracy: 0.9434\n",
            "Epoch 209/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.7516 - val_loss: 0.2787 - val_accuracy: 0.9434\n",
            "Epoch 210/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7510 - accuracy: 0.7116 - val_loss: 0.2680 - val_accuracy: 0.9623\n",
            "Epoch 211/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7865 - accuracy: 0.7411 - val_loss: 0.2741 - val_accuracy: 0.9623\n",
            "Epoch 212/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7458 - accuracy: 0.6905 - val_loss: 0.2739 - val_accuracy: 0.9623\n",
            "Epoch 213/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.7516 - val_loss: 0.2727 - val_accuracy: 0.9245\n",
            "Epoch 214/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7480 - accuracy: 0.7432 - val_loss: 0.2738 - val_accuracy: 0.9245\n",
            "Epoch 215/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7630 - accuracy: 0.7032 - val_loss: 0.2635 - val_accuracy: 0.9245\n",
            "Epoch 216/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7242 - accuracy: 0.7368 - val_loss: 0.2598 - val_accuracy: 0.9434\n",
            "Epoch 217/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.7347 - val_loss: 0.2532 - val_accuracy: 0.9623\n",
            "Epoch 218/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.7347 - val_loss: 0.2516 - val_accuracy: 0.9623\n",
            "Epoch 219/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.7347 - val_loss: 0.2591 - val_accuracy: 0.9434\n",
            "Epoch 220/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8176 - accuracy: 0.6905 - val_loss: 0.2626 - val_accuracy: 0.9434\n",
            "Epoch 221/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7639 - accuracy: 0.6863 - val_loss: 0.2661 - val_accuracy: 0.9245\n",
            "Epoch 222/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7504 - accuracy: 0.7116 - val_loss: 0.2691 - val_accuracy: 0.9623\n",
            "Epoch 223/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7137 - accuracy: 0.7284 - val_loss: 0.2712 - val_accuracy: 0.9245\n",
            "Epoch 224/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8966 - accuracy: 0.6695 - val_loss: 0.2739 - val_accuracy: 0.9434\n",
            "Epoch 225/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.7347 - val_loss: 0.2596 - val_accuracy: 0.9623\n",
            "Epoch 226/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.7242 - val_loss: 0.2503 - val_accuracy: 0.9434\n",
            "Epoch 227/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7665 - accuracy: 0.7179 - val_loss: 0.2500 - val_accuracy: 0.9434\n",
            "Epoch 228/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.7432 - val_loss: 0.2528 - val_accuracy: 0.9245\n",
            "Epoch 229/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7016 - accuracy: 0.7453 - val_loss: 0.2616 - val_accuracy: 0.9623\n",
            "Epoch 230/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7293 - accuracy: 0.7284 - val_loss: 0.2663 - val_accuracy: 0.9623\n",
            "Epoch 231/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.7389 - val_loss: 0.2665 - val_accuracy: 0.9434\n",
            "Epoch 232/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7570 - accuracy: 0.7095 - val_loss: 0.2592 - val_accuracy: 0.9245\n",
            "Epoch 233/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.7305 - val_loss: 0.2599 - val_accuracy: 0.9623\n",
            "Epoch 234/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7268 - accuracy: 0.7221 - val_loss: 0.2609 - val_accuracy: 0.9434\n",
            "Epoch 235/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.7221 - val_loss: 0.2698 - val_accuracy: 0.9245\n",
            "Epoch 236/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7055 - accuracy: 0.7768 - val_loss: 0.2689 - val_accuracy: 0.9623\n",
            "Epoch 237/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7562 - accuracy: 0.7263 - val_loss: 0.2650 - val_accuracy: 0.9434\n",
            "Epoch 238/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7667 - accuracy: 0.7200 - val_loss: 0.2693 - val_accuracy: 0.9245\n",
            "Epoch 239/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7637 - accuracy: 0.7453 - val_loss: 0.2762 - val_accuracy: 0.9245\n",
            "Epoch 240/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7833 - accuracy: 0.7179 - val_loss: 0.2734 - val_accuracy: 0.9434\n",
            "Epoch 241/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7254 - accuracy: 0.7242 - val_loss: 0.2674 - val_accuracy: 0.9434\n",
            "Epoch 242/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.7095 - val_loss: 0.2707 - val_accuracy: 0.9434\n",
            "Epoch 243/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7774 - accuracy: 0.7158 - val_loss: 0.2749 - val_accuracy: 0.9434\n",
            "Epoch 244/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7010 - accuracy: 0.7411 - val_loss: 0.2780 - val_accuracy: 0.9434\n",
            "Epoch 245/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.7411 - val_loss: 0.2746 - val_accuracy: 0.9057\n",
            "Epoch 246/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.8167 - accuracy: 0.7032 - val_loss: 0.2629 - val_accuracy: 0.9245\n",
            "Epoch 247/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8987 - accuracy: 0.6589 - val_loss: 0.2726 - val_accuracy: 0.9623\n",
            "Epoch 248/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8438 - accuracy: 0.6905 - val_loss: 0.2894 - val_accuracy: 0.9245\n",
            "Epoch 249/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7988 - accuracy: 0.6947 - val_loss: 0.2837 - val_accuracy: 0.9434\n",
            "Epoch 250/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.7768 - val_loss: 0.2825 - val_accuracy: 0.9434\n",
            "Epoch 251/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7382 - accuracy: 0.7411 - val_loss: 0.2784 - val_accuracy: 0.9245\n",
            "Epoch 252/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.7221 - val_loss: 0.2822 - val_accuracy: 0.9434\n",
            "Epoch 253/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7298 - accuracy: 0.7158 - val_loss: 0.2696 - val_accuracy: 0.9434\n",
            "Epoch 254/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7644 - accuracy: 0.7158 - val_loss: 0.2635 - val_accuracy: 0.9434\n",
            "Epoch 255/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.7621 - val_loss: 0.2674 - val_accuracy: 0.9434\n",
            "Epoch 256/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7579 - val_loss: 0.2629 - val_accuracy: 0.9623\n",
            "Epoch 257/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.7811 - val_loss: 0.2650 - val_accuracy: 0.9623\n",
            "Epoch 258/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7483 - accuracy: 0.7095 - val_loss: 0.2687 - val_accuracy: 0.9434\n",
            "Epoch 259/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7695 - accuracy: 0.7200 - val_loss: 0.2510 - val_accuracy: 0.9434\n",
            "Epoch 260/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7955 - accuracy: 0.7032 - val_loss: 0.2553 - val_accuracy: 0.9434\n",
            "Epoch 261/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6967 - accuracy: 0.7326 - val_loss: 0.2651 - val_accuracy: 0.9623\n",
            "Epoch 262/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.7621 - val_loss: 0.2630 - val_accuracy: 0.9623\n",
            "Epoch 263/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7935 - accuracy: 0.7263 - val_loss: 0.2770 - val_accuracy: 0.9434\n",
            "Epoch 264/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7481 - accuracy: 0.7116 - val_loss: 0.2773 - val_accuracy: 0.9245\n",
            "Epoch 265/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.7347 - val_loss: 0.2774 - val_accuracy: 0.9057\n",
            "Epoch 266/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.7642 - val_loss: 0.2726 - val_accuracy: 0.9245\n",
            "Epoch 267/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7669 - accuracy: 0.7137 - val_loss: 0.2615 - val_accuracy: 0.9057\n",
            "Epoch 268/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7167 - accuracy: 0.7453 - val_loss: 0.2640 - val_accuracy: 0.9057\n",
            "Epoch 269/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.7600 - val_loss: 0.2475 - val_accuracy: 0.9057\n",
            "Epoch 270/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.7684 - val_loss: 0.2503 - val_accuracy: 0.9245\n",
            "Epoch 271/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.7642 - val_loss: 0.2519 - val_accuracy: 0.9434\n",
            "Epoch 272/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8320 - accuracy: 0.6779 - val_loss: 0.2586 - val_accuracy: 0.9434\n",
            "Epoch 273/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.7200 - val_loss: 0.2522 - val_accuracy: 0.9623\n",
            "Epoch 274/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7974 - accuracy: 0.6905 - val_loss: 0.2576 - val_accuracy: 0.9623\n",
            "Epoch 275/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6987 - accuracy: 0.7389 - val_loss: 0.2648 - val_accuracy: 0.9434\n",
            "Epoch 276/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.7453 - val_loss: 0.2634 - val_accuracy: 0.9434\n",
            "Epoch 277/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7524 - accuracy: 0.7242 - val_loss: 0.2381 - val_accuracy: 0.9623\n",
            "Epoch 278/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.7432 - val_loss: 0.2401 - val_accuracy: 0.9811\n",
            "Epoch 279/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7667 - accuracy: 0.7200 - val_loss: 0.2537 - val_accuracy: 0.9623\n",
            "Epoch 280/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7663 - accuracy: 0.7326 - val_loss: 0.2682 - val_accuracy: 0.9245\n",
            "Epoch 281/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.7453 - val_loss: 0.2470 - val_accuracy: 0.9245\n",
            "Epoch 282/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.7558 - val_loss: 0.2525 - val_accuracy: 0.9434\n",
            "Epoch 283/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7145 - accuracy: 0.7221 - val_loss: 0.2514 - val_accuracy: 0.9057\n",
            "Epoch 284/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7637 - accuracy: 0.7158 - val_loss: 0.2476 - val_accuracy: 0.9434\n",
            "Epoch 285/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7409 - accuracy: 0.7200 - val_loss: 0.2425 - val_accuracy: 0.9434\n",
            "Epoch 286/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.7958 - val_loss: 0.2465 - val_accuracy: 0.9434\n",
            "Epoch 287/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7789 - val_loss: 0.2509 - val_accuracy: 0.9434\n",
            "Epoch 288/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6977 - accuracy: 0.7284 - val_loss: 0.2449 - val_accuracy: 0.9245\n",
            "Epoch 289/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.7537 - val_loss: 0.2391 - val_accuracy: 0.9434\n",
            "Epoch 290/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.7537 - val_loss: 0.2551 - val_accuracy: 0.9245\n",
            "Epoch 291/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6680 - accuracy: 0.7495 - val_loss: 0.2602 - val_accuracy: 0.9057\n",
            "Epoch 292/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7347 - val_loss: 0.2587 - val_accuracy: 0.9245\n",
            "Epoch 293/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.7853 - val_loss: 0.2522 - val_accuracy: 0.9245\n",
            "Epoch 294/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7836 - accuracy: 0.7158 - val_loss: 0.2616 - val_accuracy: 0.9434\n",
            "Epoch 295/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8093 - accuracy: 0.6821 - val_loss: 0.2481 - val_accuracy: 0.9623\n",
            "Epoch 296/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.7284 - val_loss: 0.2386 - val_accuracy: 0.9623\n",
            "Epoch 297/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7566 - accuracy: 0.7242 - val_loss: 0.2457 - val_accuracy: 0.9434\n",
            "Epoch 298/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6528 - accuracy: 0.7663 - val_loss: 0.2456 - val_accuracy: 0.9434\n",
            "Epoch 299/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7608 - accuracy: 0.7347 - val_loss: 0.2482 - val_accuracy: 0.9434\n",
            "Epoch 300/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.7558 - val_loss: 0.2517 - val_accuracy: 0.9245\n",
            "Epoch 301/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7318 - accuracy: 0.7495 - val_loss: 0.2563 - val_accuracy: 0.9434\n",
            "Epoch 302/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7053 - accuracy: 0.7453 - val_loss: 0.2630 - val_accuracy: 0.9245\n",
            "Epoch 303/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6972 - accuracy: 0.7474 - val_loss: 0.2557 - val_accuracy: 0.9245\n",
            "Epoch 304/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.7621 - val_loss: 0.2656 - val_accuracy: 0.9245\n",
            "Epoch 305/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.7389 - val_loss: 0.2702 - val_accuracy: 0.9434\n",
            "Epoch 306/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7115 - accuracy: 0.7242 - val_loss: 0.2610 - val_accuracy: 0.9434\n",
            "Epoch 307/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7582 - accuracy: 0.7242 - val_loss: 0.2624 - val_accuracy: 0.9245\n",
            "Epoch 308/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7323 - accuracy: 0.7495 - val_loss: 0.2499 - val_accuracy: 0.9245\n",
            "Epoch 309/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.7453 - val_loss: 0.2506 - val_accuracy: 0.9057\n",
            "Epoch 310/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.7558 - val_loss: 0.2513 - val_accuracy: 0.9245\n",
            "Epoch 311/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.7537 - val_loss: 0.2690 - val_accuracy: 0.9245\n",
            "Epoch 312/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.7242 - val_loss: 0.2699 - val_accuracy: 0.9434\n",
            "Epoch 313/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6274 - accuracy: 0.7642 - val_loss: 0.2642 - val_accuracy: 0.9623\n",
            "Epoch 314/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7364 - accuracy: 0.7032 - val_loss: 0.2544 - val_accuracy: 0.9245\n",
            "Epoch 315/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.7474 - val_loss: 0.2538 - val_accuracy: 0.9245\n",
            "Epoch 316/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6356 - accuracy: 0.7621 - val_loss: 0.2463 - val_accuracy: 0.9434\n",
            "Epoch 317/500\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.7542 - accuracy: 0.7326 - val_loss: 0.2471 - val_accuracy: 0.9623\n",
            "Epoch 318/500\n",
            "30/30 [==============================] - 0s 11ms/step - loss: 0.6981 - accuracy: 0.7474 - val_loss: 0.2532 - val_accuracy: 0.9623\n",
            "Epoch 319/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.7411 - val_loss: 0.2576 - val_accuracy: 0.9623\n",
            "Epoch 320/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.7200 - val_loss: 0.2701 - val_accuracy: 0.9434\n",
            "Epoch 321/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.7684 - val_loss: 0.2486 - val_accuracy: 0.9245\n",
            "Epoch 322/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.7493 - accuracy: 0.7116 - val_loss: 0.2662 - val_accuracy: 0.9434\n",
            "Epoch 323/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.6864 - accuracy: 0.7411 - val_loss: 0.2695 - val_accuracy: 0.9434\n",
            "Epoch 324/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.7537 - val_loss: 0.2524 - val_accuracy: 0.9623\n",
            "Epoch 325/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7164 - accuracy: 0.7474 - val_loss: 0.2578 - val_accuracy: 0.9245\n",
            "Epoch 326/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.7600 - val_loss: 0.2579 - val_accuracy: 0.9623\n",
            "Epoch 327/500\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.6814 - accuracy: 0.7453 - val_loss: 0.2357 - val_accuracy: 0.9623\n",
            "Epoch 328/500\n",
            "30/30 [==============================] - 0s 10ms/step - loss: 0.6398 - accuracy: 0.7537 - val_loss: 0.2304 - val_accuracy: 0.9811\n",
            "Epoch 329/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.7368 - val_loss: 0.2325 - val_accuracy: 0.9434\n",
            "Epoch 330/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.7179 - val_loss: 0.2424 - val_accuracy: 0.9245\n",
            "Epoch 331/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7282 - accuracy: 0.7411 - val_loss: 0.2504 - val_accuracy: 0.9057\n",
            "Epoch 332/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.7558 - val_loss: 0.2389 - val_accuracy: 0.9245\n",
            "Epoch 333/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7642 - accuracy: 0.7347 - val_loss: 0.2417 - val_accuracy: 0.9245\n",
            "Epoch 334/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7584 - accuracy: 0.7347 - val_loss: 0.2410 - val_accuracy: 0.9434\n",
            "Epoch 335/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.7642 - val_loss: 0.2385 - val_accuracy: 0.9434\n",
            "Epoch 336/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7654 - accuracy: 0.7221 - val_loss: 0.2279 - val_accuracy: 0.9434\n",
            "Epoch 337/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.7663 - val_loss: 0.2279 - val_accuracy: 0.9245\n",
            "Epoch 338/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.7621 - val_loss: 0.2412 - val_accuracy: 0.9245\n",
            "Epoch 339/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7073 - accuracy: 0.7347 - val_loss: 0.2416 - val_accuracy: 0.9434\n",
            "Epoch 340/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.7158 - val_loss: 0.2431 - val_accuracy: 0.9245\n",
            "Epoch 341/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7334 - accuracy: 0.7411 - val_loss: 0.2414 - val_accuracy: 0.9623\n",
            "Epoch 342/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.7305 - val_loss: 0.2365 - val_accuracy: 0.9245\n",
            "Epoch 343/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7260 - accuracy: 0.7284 - val_loss: 0.2401 - val_accuracy: 0.9245\n",
            "Epoch 344/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8335 - accuracy: 0.6800 - val_loss: 0.2300 - val_accuracy: 0.9811\n",
            "Epoch 345/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7018 - accuracy: 0.7305 - val_loss: 0.2445 - val_accuracy: 0.9434\n",
            "Epoch 346/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.7832 - val_loss: 0.2497 - val_accuracy: 0.9245\n",
            "Epoch 347/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.7242 - val_loss: 0.2590 - val_accuracy: 0.9245\n",
            "Epoch 348/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7307 - accuracy: 0.7200 - val_loss: 0.2492 - val_accuracy: 0.9434\n",
            "Epoch 349/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.7537 - val_loss: 0.2517 - val_accuracy: 0.9057\n",
            "Epoch 350/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7539 - accuracy: 0.7284 - val_loss: 0.2484 - val_accuracy: 0.9434\n",
            "Epoch 351/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7593 - accuracy: 0.6989 - val_loss: 0.2402 - val_accuracy: 0.9434\n",
            "Epoch 352/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.7537 - val_loss: 0.2310 - val_accuracy: 0.9623\n",
            "Epoch 353/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.7411 - val_loss: 0.2312 - val_accuracy: 0.9434\n",
            "Epoch 354/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6343 - accuracy: 0.7537 - val_loss: 0.2330 - val_accuracy: 0.9434\n",
            "Epoch 355/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7205 - accuracy: 0.7600 - val_loss: 0.2345 - val_accuracy: 0.9623\n",
            "Epoch 356/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.7453 - val_loss: 0.2319 - val_accuracy: 0.9434\n",
            "Epoch 357/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7111 - accuracy: 0.7432 - val_loss: 0.2378 - val_accuracy: 0.9434\n",
            "Epoch 358/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.7642 - val_loss: 0.2314 - val_accuracy: 0.9434\n",
            "Epoch 359/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.7789 - val_loss: 0.2307 - val_accuracy: 0.9245\n",
            "Epoch 360/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7575 - accuracy: 0.7263 - val_loss: 0.2334 - val_accuracy: 0.9245\n",
            "Epoch 361/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.7474 - val_loss: 0.2241 - val_accuracy: 0.9434\n",
            "Epoch 362/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7101 - accuracy: 0.7389 - val_loss: 0.2250 - val_accuracy: 0.9434\n",
            "Epoch 363/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7227 - accuracy: 0.7158 - val_loss: 0.2301 - val_accuracy: 0.9623\n",
            "Epoch 364/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.8280 - accuracy: 0.7074 - val_loss: 0.2266 - val_accuracy: 0.9434\n",
            "Epoch 365/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.7495 - val_loss: 0.2216 - val_accuracy: 0.9811\n",
            "Epoch 366/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.7663 - val_loss: 0.2249 - val_accuracy: 0.9811\n",
            "Epoch 367/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.7263 - val_loss: 0.2328 - val_accuracy: 0.9623\n",
            "Epoch 368/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7390 - accuracy: 0.7053 - val_loss: 0.2521 - val_accuracy: 0.9623\n",
            "Epoch 369/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7251 - accuracy: 0.7284 - val_loss: 0.2512 - val_accuracy: 0.9623\n",
            "Epoch 370/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.7684 - val_loss: 0.2379 - val_accuracy: 0.9623\n",
            "Epoch 371/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.7474 - val_loss: 0.2361 - val_accuracy: 0.9623\n",
            "Epoch 372/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6624 - accuracy: 0.7663 - val_loss: 0.2380 - val_accuracy: 0.9623\n",
            "Epoch 373/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.7600 - val_loss: 0.2319 - val_accuracy: 0.9434\n",
            "Epoch 374/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.7600 - val_loss: 0.2328 - val_accuracy: 0.9245\n",
            "Epoch 375/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.7537 - val_loss: 0.2318 - val_accuracy: 0.9434\n",
            "Epoch 376/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7143 - accuracy: 0.7158 - val_loss: 0.2358 - val_accuracy: 0.9434\n",
            "Epoch 377/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7604 - accuracy: 0.7347 - val_loss: 0.2308 - val_accuracy: 0.9434\n",
            "Epoch 378/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7425 - accuracy: 0.7053 - val_loss: 0.2250 - val_accuracy: 0.9434\n",
            "Epoch 379/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.7642 - val_loss: 0.2525 - val_accuracy: 0.9245\n",
            "Epoch 380/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.7432 - val_loss: 0.2457 - val_accuracy: 0.9434\n",
            "Epoch 381/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5976 - accuracy: 0.7747 - val_loss: 0.2499 - val_accuracy: 0.9245\n",
            "Epoch 382/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.7305 - val_loss: 0.2490 - val_accuracy: 0.9245\n",
            "Epoch 383/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.7558 - val_loss: 0.2494 - val_accuracy: 0.9057\n",
            "Epoch 384/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7156 - accuracy: 0.7158 - val_loss: 0.2360 - val_accuracy: 0.9245\n",
            "Epoch 385/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.7537 - val_loss: 0.2413 - val_accuracy: 0.9434\n",
            "Epoch 386/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7558 - val_loss: 0.2415 - val_accuracy: 0.9623\n",
            "Epoch 387/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.7789 - val_loss: 0.2374 - val_accuracy: 0.9434\n",
            "Epoch 388/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.7705 - val_loss: 0.2197 - val_accuracy: 0.9623\n",
            "Epoch 389/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7749 - accuracy: 0.7200 - val_loss: 0.2281 - val_accuracy: 0.9623\n",
            "Epoch 390/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6886 - accuracy: 0.7411 - val_loss: 0.2309 - val_accuracy: 0.9623\n",
            "Epoch 391/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.7516 - val_loss: 0.2355 - val_accuracy: 0.9623\n",
            "Epoch 392/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.5842 - accuracy: 0.7811 - val_loss: 0.2273 - val_accuracy: 0.9623\n",
            "Epoch 393/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6690 - accuracy: 0.7684 - val_loss: 0.2405 - val_accuracy: 0.9623\n",
            "Epoch 394/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7408 - accuracy: 0.7284 - val_loss: 0.2437 - val_accuracy: 0.9623\n",
            "Epoch 395/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7547 - accuracy: 0.7011 - val_loss: 0.2556 - val_accuracy: 0.9623\n",
            "Epoch 396/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7144 - accuracy: 0.7368 - val_loss: 0.2539 - val_accuracy: 0.9623\n",
            "Epoch 397/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.7432 - val_loss: 0.2361 - val_accuracy: 0.9623\n",
            "Epoch 398/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.7579 - val_loss: 0.2356 - val_accuracy: 0.9434\n",
            "Epoch 399/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.7600 - val_loss: 0.2371 - val_accuracy: 0.9434\n",
            "Epoch 400/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6314 - accuracy: 0.7747 - val_loss: 0.2343 - val_accuracy: 0.9623\n",
            "Epoch 401/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.7579 - val_loss: 0.2341 - val_accuracy: 0.9623\n",
            "Epoch 402/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.7453 - val_loss: 0.2454 - val_accuracy: 0.9623\n",
            "Epoch 403/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.7411 - val_loss: 0.2336 - val_accuracy: 0.9623\n",
            "Epoch 404/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.7684 - val_loss: 0.2364 - val_accuracy: 0.9434\n",
            "Epoch 405/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.7684 - val_loss: 0.2478 - val_accuracy: 0.9434\n",
            "Epoch 406/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.7432 - val_loss: 0.2367 - val_accuracy: 0.9434\n",
            "Epoch 407/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.7284 - val_loss: 0.2296 - val_accuracy: 0.9623\n",
            "Epoch 408/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.7516 - val_loss: 0.2217 - val_accuracy: 0.9623\n",
            "Epoch 409/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.7474 - val_loss: 0.2332 - val_accuracy: 0.9623\n",
            "Epoch 410/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.7579 - val_loss: 0.2179 - val_accuracy: 0.9811\n",
            "Epoch 411/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.7537 - val_loss: 0.2197 - val_accuracy: 0.9623\n",
            "Epoch 412/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6989 - accuracy: 0.7326 - val_loss: 0.2267 - val_accuracy: 0.9623\n",
            "Epoch 413/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7631 - accuracy: 0.7137 - val_loss: 0.2194 - val_accuracy: 0.9623\n",
            "Epoch 414/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7048 - accuracy: 0.7453 - val_loss: 0.2181 - val_accuracy: 0.9623\n",
            "Epoch 415/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.7747 - val_loss: 0.2211 - val_accuracy: 0.9623\n",
            "Epoch 416/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.7663 - val_loss: 0.2339 - val_accuracy: 0.9811\n",
            "Epoch 417/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7389 - val_loss: 0.2375 - val_accuracy: 0.9811\n",
            "Epoch 418/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.7432 - val_loss: 0.2340 - val_accuracy: 0.9434\n",
            "Epoch 419/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6098 - accuracy: 0.7853 - val_loss: 0.2160 - val_accuracy: 0.9811\n",
            "Epoch 420/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7286 - accuracy: 0.7200 - val_loss: 0.2179 - val_accuracy: 0.9623\n",
            "Epoch 421/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.7516 - val_loss: 0.2210 - val_accuracy: 0.9623\n",
            "Epoch 422/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.7537 - val_loss: 0.2214 - val_accuracy: 0.9623\n",
            "Epoch 423/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.7853 - val_loss: 0.2265 - val_accuracy: 0.9434\n",
            "Epoch 424/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7705 - val_loss: 0.2351 - val_accuracy: 0.9245\n",
            "Epoch 425/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7570 - accuracy: 0.7158 - val_loss: 0.2309 - val_accuracy: 0.9434\n",
            "Epoch 426/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7143 - accuracy: 0.7432 - val_loss: 0.2303 - val_accuracy: 0.9434\n",
            "Epoch 427/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.7242 - val_loss: 0.2272 - val_accuracy: 0.9434\n",
            "Epoch 428/500\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.7179 - val_loss: 0.2270 - val_accuracy: 0.9434\n",
            "Epoch 429/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7049 - accuracy: 0.7305 - val_loss: 0.2365 - val_accuracy: 0.9245\n",
            "Epoch 430/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6472 - accuracy: 0.7579 - val_loss: 0.2379 - val_accuracy: 0.9434\n",
            "Epoch 431/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.7600 - val_loss: 0.2236 - val_accuracy: 0.9434\n",
            "Epoch 432/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.7516 - val_loss: 0.2273 - val_accuracy: 0.9434\n",
            "Epoch 433/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7535 - accuracy: 0.7347 - val_loss: 0.2249 - val_accuracy: 0.9245\n",
            "Epoch 434/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7308 - accuracy: 0.7347 - val_loss: 0.2322 - val_accuracy: 0.9434\n",
            "Epoch 435/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7495 - val_loss: 0.2240 - val_accuracy: 0.9623\n",
            "Epoch 436/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7398 - accuracy: 0.7389 - val_loss: 0.2256 - val_accuracy: 0.9245\n",
            "Epoch 437/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.7537 - val_loss: 0.2238 - val_accuracy: 0.9245\n",
            "Epoch 438/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7937 - val_loss: 0.2211 - val_accuracy: 0.9623\n",
            "Epoch 439/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.7516 - val_loss: 0.2410 - val_accuracy: 0.9623\n",
            "Epoch 440/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.7196 - accuracy: 0.7200 - val_loss: 0.2377 - val_accuracy: 0.9434\n",
            "Epoch 441/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.7411 - val_loss: 0.2257 - val_accuracy: 0.9434\n",
            "Epoch 442/500\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.7141 - accuracy: 0.7221 - val_loss: 0.2310 - val_accuracy: 0.9623\n",
            "Epoch 443/500\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6588 - accuracy: 0.7579 - val_loss: 0.2364 - val_accuracy: 0.9434\n",
            "Epoch 444/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.6773 - accuracy: 0.7432 - val_loss: 0.2305 - val_accuracy: 0.9623\n",
            "Epoch 445/500\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6780 - accuracy: 0.7537 - val_loss: 0.2309 - val_accuracy: 0.9434\n",
            "Epoch 446/500\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.6398 - accuracy: 0.7305 - val_loss: 0.2399 - val_accuracy: 0.9623\n",
            "Epoch 447/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.6472 - accuracy: 0.7747 - val_loss: 0.2334 - val_accuracy: 0.9434\n",
            "Epoch 448/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.6353 - accuracy: 0.7874 - val_loss: 0.2256 - val_accuracy: 0.9623\n",
            "Epoch 449/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.6230 - accuracy: 0.7474 - val_loss: 0.2368 - val_accuracy: 0.9623\n",
            "Epoch 450/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.7569 - accuracy: 0.7347 - val_loss: 0.2379 - val_accuracy: 0.9623\n",
            "Epoch 451/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.6477 - accuracy: 0.7579 - val_loss: 0.2263 - val_accuracy: 0.9623\n",
            "Epoch 452/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.7004 - accuracy: 0.7284 - val_loss: 0.2288 - val_accuracy: 0.9623\n",
            "Epoch 453/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.6275 - accuracy: 0.7537 - val_loss: 0.2319 - val_accuracy: 0.9623\n",
            "Epoch 454/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.6654 - accuracy: 0.7726 - val_loss: 0.2329 - val_accuracy: 0.9623\n",
            "Epoch 455/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.6634 - accuracy: 0.7642 - val_loss: 0.2290 - val_accuracy: 0.9434\n",
            "Epoch 456/500\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.7694 - accuracy: 0.6989 - val_loss: 0.2263 - val_accuracy: 0.9434\n",
            "Epoch 457/500\n",
            "30/30 [==============================] - 0s 9ms/step - loss: 0.6240 - accuracy: 0.7642 - val_loss: 0.2389 - val_accuracy: 0.9434\n",
            "Epoch 458/500\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.7138 - accuracy: 0.7368 - val_loss: 0.2291 - val_accuracy: 0.9245\n",
            "Epoch 459/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6620 - accuracy: 0.7389 - val_loss: 0.2271 - val_accuracy: 0.9245\n",
            "Epoch 460/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6676 - accuracy: 0.7663 - val_loss: 0.2438 - val_accuracy: 0.9434\n",
            "Epoch 461/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7432 - val_loss: 0.2252 - val_accuracy: 0.9434\n",
            "Epoch 462/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6561 - accuracy: 0.7705 - val_loss: 0.2325 - val_accuracy: 0.9434\n",
            "Epoch 463/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6353 - accuracy: 0.7621 - val_loss: 0.2275 - val_accuracy: 0.9434\n",
            "Epoch 464/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.5901 - accuracy: 0.7937 - val_loss: 0.2322 - val_accuracy: 0.9434\n",
            "Epoch 465/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7543 - accuracy: 0.7263 - val_loss: 0.2236 - val_accuracy: 0.9434\n",
            "Epoch 466/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7330 - accuracy: 0.7284 - val_loss: 0.2238 - val_accuracy: 0.9434\n",
            "Epoch 467/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.7516 - val_loss: 0.2233 - val_accuracy: 0.9245\n",
            "Epoch 468/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.7558 - val_loss: 0.2220 - val_accuracy: 0.9434\n",
            "Epoch 469/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7187 - accuracy: 0.7263 - val_loss: 0.2316 - val_accuracy: 0.9245\n",
            "Epoch 470/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.6989 - val_loss: 0.2470 - val_accuracy: 0.9434\n",
            "Epoch 471/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.7663 - val_loss: 0.2420 - val_accuracy: 0.9434\n",
            "Epoch 472/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.7768 - val_loss: 0.2289 - val_accuracy: 0.9434\n",
            "Epoch 473/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7486 - accuracy: 0.7200 - val_loss: 0.2412 - val_accuracy: 0.9434\n",
            "Epoch 474/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.7432 - val_loss: 0.2426 - val_accuracy: 0.9245\n",
            "Epoch 475/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6741 - accuracy: 0.7411 - val_loss: 0.2408 - val_accuracy: 0.9245\n",
            "Epoch 476/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.7663 - val_loss: 0.2303 - val_accuracy: 0.9623\n",
            "Epoch 477/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7180 - accuracy: 0.7116 - val_loss: 0.2118 - val_accuracy: 0.9434\n",
            "Epoch 478/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7046 - accuracy: 0.7368 - val_loss: 0.2110 - val_accuracy: 0.9434\n",
            "Epoch 479/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.7663 - val_loss: 0.2051 - val_accuracy: 0.9623\n",
            "Epoch 480/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7516 - val_loss: 0.2254 - val_accuracy: 0.9623\n",
            "Epoch 481/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.7621 - val_loss: 0.2274 - val_accuracy: 0.9434\n",
            "Epoch 482/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.7474 - val_loss: 0.2185 - val_accuracy: 0.9623\n",
            "Epoch 483/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.7495 - val_loss: 0.2222 - val_accuracy: 0.9623\n",
            "Epoch 484/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.7642 - val_loss: 0.2120 - val_accuracy: 0.9623\n",
            "Epoch 485/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.7747 - val_loss: 0.2113 - val_accuracy: 0.9623\n",
            "Epoch 486/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6819 - accuracy: 0.7642 - val_loss: 0.2178 - val_accuracy: 0.9623\n",
            "Epoch 487/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.7621 - val_loss: 0.2089 - val_accuracy: 0.9623\n",
            "Epoch 488/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7768 - val_loss: 0.2178 - val_accuracy: 0.9623\n",
            "Epoch 489/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6717 - accuracy: 0.7579 - val_loss: 0.2366 - val_accuracy: 0.9623\n",
            "Epoch 490/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6967 - accuracy: 0.7642 - val_loss: 0.2316 - val_accuracy: 0.9434\n",
            "Epoch 491/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7529 - accuracy: 0.7474 - val_loss: 0.2401 - val_accuracy: 0.9434\n",
            "Epoch 492/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7805 - accuracy: 0.7011 - val_loss: 0.2246 - val_accuracy: 0.9434\n",
            "Epoch 493/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.7389 - val_loss: 0.2274 - val_accuracy: 0.9434\n",
            "Epoch 494/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.7472 - accuracy: 0.7347 - val_loss: 0.2415 - val_accuracy: 0.9245\n",
            "Epoch 495/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6987 - accuracy: 0.7495 - val_loss: 0.2548 - val_accuracy: 0.9245\n",
            "Epoch 496/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.7600 - val_loss: 0.2404 - val_accuracy: 0.9434\n",
            "Epoch 497/500\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6392 - accuracy: 0.7600 - val_loss: 0.2245 - val_accuracy: 0.9623\n",
            "Epoch 498/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.7474 - val_loss: 0.2238 - val_accuracy: 0.9623\n",
            "Epoch 499/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.7347 - val_loss: 0.2182 - val_accuracy: 0.9245\n",
            "Epoch 500/500\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.7411 - val_loss: 0.2095 - val_accuracy: 0.9434\n",
            "Minimum Validation Loss: 0.2051\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "metadata": {
        "id": "ID0-l5vV7Rzf"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM classifier using using linear kernel \n",
        "from sklearn.svm import SVC  \n",
        "model_svm = SVC(kernel='linear') \n",
        "\n",
        "#trained svm classifier\n",
        "model_svm.fit(y_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "LCN2mVXP8l3M",
        "outputId": "8d17824f-e647-4144-970a-eba9f26d5680"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-927163db2709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#trained svm classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             )\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    991\u001b[0m         )\n\u001b[1;32m    992\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     )\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (528, 11) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the necessary packages and libaries\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LN_fAm9D8oYi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e6Y7nj2qC03B"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
        "rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
        "poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
        "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "zQ6N5AesCqaM",
        "outputId": "79df0d3c-85b4-419d-f77c-0e3602e4587e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-984c8e56b837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_function_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrbf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_function_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'poly'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_function_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_function_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ovo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             )\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    991\u001b[0m         )\n\u001b[1;32m    992\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     )\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (528, 11) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "5TooOF-tC4M_"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn5 = KNeighborsClassifier(n_neighbors = 5)\n",
        "knn1 = KNeighborsClassifier(n_neighbors=1)"
      ],
      "metadata": {
        "id": "La5CcJt2EAt9"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn5.fit(X_train, y_train)\n",
        "knn1.fit(X_train, y_train)\n",
        "\n",
        "y_pred_5 = knn5.predict(X_test)\n",
        "y_pred_1 = knn1.predict(X_test)"
      ],
      "metadata": {
        "id": "mAhv4087EIOw"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy with k=5\", accuracy_score(y_test, y_pred_5)*100)\n",
        "print(\"Accuracy with k=1\", accuracy_score(y_test, y_pred_1)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VYsDkfpENSp",
        "outputId": "56cae790-009e-4906-8da0-df26d0cab311"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with k=5 56.27705627705628\n",
            "Accuracy with k=1 56.27705627705628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQGrJ_8tFoCM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}